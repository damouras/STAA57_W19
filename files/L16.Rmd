---
title: "L16 - Causality & Experiments"
author: "Sotirios Damouras"
output:
  ioslides_presentation:
    transition: 0
    logo: img/logo.png
---

<!-- 
output: html_notebook 

output:
  ioslides_presentation:
    transition: 0
    logo: img/logo.png
-->


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(123)
library(tidyverse)
library(broom)
```

## Lecture Goals 

- Understand concept of *causality* 
    + Distinguish causation from association
    + Beware of *confounding* in observational studies
- Use *control variables* to limit confounding
- Use *experiments* to assess causal relations  
    
- Readings 
    + [ISRS](https://www.openintro.org/download.php?file=isrs1_tablet&referrer=/stat/textbook.php): ch. 1.3-5



## Association & Causation 

- *Association/Dependence*  describes any *statistical* relationship between variables
    + E.g. if $X$ is large, then $Y$ will *likely* be large, & vice-versa
    + Association is *symmetric* ($X \leftrightarrow Y$) 

- *Causation/Causality* describes **cause-effect** relationship between variables
    + E.g. $X$ is (partially) responsible for changes in $Y$
    + Causation is *asymmetric* ($X \rightarrow Y$)

## Association vs Causation 

- Type of relation determines its *practical use*

- Associations used for *prediction*
    + Just *observe* event & try to *predict* its outcome ($Y$) based on available information ($X$) 

- Causual relationships used for *intervention*
    + Can actually *manipulate* ($X$) in order to *change* event's outcome ($Y$) 

## Regression

- Regression model describes *"relationship"* between response ($Y$) and explanatory ($X$) variables

- Plug-in nature of regression function ($X\rightarrow f(X)=\hat{Y}$) suggests that $X$ *causes* $Y$
  
- Causal interpretation is generally **incorrect**
       + Unless data come from *experiment*, i.e. generated by intervention


## Example

- Consider hypothetical causal model with variables  
    + $X$:  ice cream sales   
    + $Y$:  wildfires area
    + $Z$:  average temperature 
    
   and (linear) causal relationships

$$X = a + b Z + \textrm{err}_X, \quad Y = c + d Z + \textrm{err}_Y$$
![](./img/XYZ.png)



## Example 

- Simulate data from causal model (no intervention) 
```{r}
sim = tibble( Z = 30 + 10 * rnorm(100),
              X = 20 + 3 * Z + 20*rnorm(100), 
              Y = 50 + 1 * Z + 10*rnorm(100))
```
- `rnorm()` generates real random numbers

```{r, fig.width = 3, fig.height=2 }
tibble(x=rnorm(1000)) %>% ggplot(aes(x=x)) + geom_density()
```

## Example 

- Simulated data scatterplots 
```{r, echo=FALSE, fig.width = 7, fig.height=5, message = FALSE, warning = FALSE }
library(GGally)
ggpairs(sim, lower=list(continuous="smooth"))
```


## Association

- Variables $X,Y$ are *associated*, by virtue of being caused by $Z$ 
    + Relationship can be described by regression
```{r, collapse = TRUE}
lm( Y ~ X, data = sim) %>% tidy()
```
- *Perfectly OK* to use model for prediction:
    + Predict wildfire severity based on ice cream sales 

- *Not OK* to use model for intervention
    + Cannot prevent wildfires by banning ice cream

## Causation

- In an experiment, we can *manipulate* variables 
    + Intervention in causal variable propagated to affected variables
    + Intervention in non-causal variable is inconsequential, and breaks up spurious associations

![](./img/causal.png)



## Example

- Experiment: control causal variable $Z$
```{r, collapse=TRUE}
sim %>% 
  mutate( Z = seq( from = min(Z), to = max(Z), length.out = 100), 
          X = 20 + 3 * Z + 20*rnorm(100),
          Y = 50 + 1 * Z + 10*rnorm(100) ) %>% 
  lm(Y ~ Z, data = .) %>% tidy()
```

## Example (con't)

- Experiment: control non-causal variable $X$
```{r, collapse=TRUE}
sim %>% 
  mutate( X = seq(min(X), max(X), length.out = 100))  %>% 
  lm(Y ~ X, data = .) %>% tidy()
```

## Confounding Variables

- *Confounder*: variable that influences both dependent & independent variables, causing *spurious* (i.e. non-causal) association
    + E.g. variable $Z$ considered previously

- Confounding prevents us from confidently drawing causal inferences from observational data
    + Confounding does not affect predictions
    
- Effect of *known* confounders can be *controlled* by including them in the model
    + Controlling does not address potential *unknown* confounders


## Example

- Include confounder ($Z$) *without* intervention

```{r, collapse=TRUE}
sim %>% 
  mutate( X = 20 + 3 * Z + 20*rnorm(100) )  %>% 
  lm(Y ~ X + Z, data = .) %>% tidy()
```


## Simpson's Paradox

- Extreme version of confounding, where association between $X$ & $Y$ is *reversed* when additional variable $Z$ is considered


```{r, echo=FALSE, fig.width=7, fig.height=4}
set.seed(123)
n=25; N = 3*n
X = c( rnorm(n,3,1), rnorm(n,5,1), rnorm(n,7,1) )
Z = c(rep("A",n), rep("B",n), rep("C",n))
Y = 10 - 2*X + c(rep(0,n), rep(15,n), rep(30,n)) + 2* rnorm(N)
tibble( X=X, Y=Y, Z=Z ) %>%
  ggplot( aes(x=X, y=Y) ) + 
  geom_point( aes(col=Z)) + 
  geom_smooth( method = "lm", col = 1) + 
  geom_smooth( aes(col=Z), method = "lm")  


# tibble( X=X, Y=Y, Z=Z ) %>%
#   ggplot( aes(x=X, y=Y) ) + 
#   geom_point()+
#   geom_smooth( method = "lm" ) 
# 
# tibble( X=X, Y=Y, Z=Z ) %>%
#   ggplot( aes(x=X, y=Y, col = Z) ) + 
#   geom_point( ) + 
#   geom_smooth( method = "lm") + 
#   theme(legend.justification = c(0, 1), legend.position = c(0, 1))
  
```


## Example

- 1973 UC Berkeley admissions data
    + Apparent gender bias in acceptance rate

```{r, echo = FALSE, fig.width=5, fig.height=4}
ucb_adm = 
  tibble( dept = rep(LETTERS[1:6],2),
        sex = c(rep("M",6), rep("F",6)),
        applicants = c( 825, 560, 325, 417, 191, 373,
                        108, 025, 593, 375, 393, 341),
        adm_rate = c(   .62, .63, .37, .33, .28, .06,
                        .82, .68, .34, .35, .24, .07) ) %>% 
  mutate( admitted = round(applicants * adm_rate),
          declined = applicants - admitted ) %>% 
  gather( decision, count, 5:6)

# ucb_adm %>% 
#   group_by(decision, sex) %>% 
#   summarise( count = sum(count) ) %>% 
#   ggplot(aes( x = sex, y = count, fill = decision) )+ 
#     geom_bar( stat = "identity", position = "fill" ) +
#     ylab("proportion")

ucb_adm %>% 
  group_by(decision, sex) %>% 
  summarise( count = sum(count) ) %>% 
  ggplot(aes( x = sex, y = count, fill = decision) )+ 
    geom_bar( stat = "identity" ) 
```

## Example (cont'd)

- Gender bias *reverses* when considering different *departments* (confounder)

```{r, echo = FALSE,  fig.width= 7, fig.height = 4 }
ucb_adm %>% 
  ggplot(aes( x = sex, y = count, fill = decision) )+ 
    geom_bar( stat = "identity") +
    ylab("proportion") + 
  facet_grid( ~dept, labeller = "label_both")

```


## Randomized Controlled Trials

- Gold standard of scientific evidence is *Randomized Controlled Trial (RCT)* 

- *Controll* variables that can be manipulated
     + Variables of *interest* are assigned to desired *treatment*, e.g. drug or placebo 
     + *Nuisance* variables are kept constant or distributed evenly (*blocking*), e.g. same gender ratio for each treatment
     
- *Randomize* for variables that cannot be manipulated
     + Randomly assign subjects to treatments, to account for
variables that cannot be controlled (prevent bias)


## Statistical Skepticism

![](img/correlation.png)
(https://imgs.xkcd.com/comics/correlation.png)



